2025-01-09 22:47:03.115 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:47:03.137 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 22:47:03.138 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 22:47:05.024 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:47:05.894 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2025-01-09 22:47:05.895 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:47:05.911 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2025-01-09 22:47:05.912 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:47:05.912 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2025-01-09 22:47:05.912 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:47:05.912 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2025-01-09 22:47:05.913 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2025-01-09 22:47:06.019 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 22:47:06.020 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 22:47:06.021 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 22:50:18.277 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:50:18.306 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 22:50:18.306 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 22:50:18.621 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2025-01-09 22:50:18.622 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:50:18.623 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2025-01-09 22:50:18.624 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:50:18.624 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2025-01-09 22:50:18.625 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:50:18.625 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2025-01-09 22:50:18.625 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2025-01-09 22:50:18.741 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 22:50:18.741 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 22:50:18.741 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 22:50:20.694 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:51:13.369 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:51:13.388 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 22:51:13.389 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 22:51:13.621 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2025-01-09 22:51:13.622 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:51:13.623 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2025-01-09 22:51:13.624 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:51:13.624 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2025-01-09 22:51:13.625 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:51:13.625 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2025-01-09 22:51:13.625 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2025-01-09 22:51:13.749 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 22:51:13.750 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 22:51:13.750 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 22:51:15.710 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:53:41.402 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:53:41.426 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 22:53:41.427 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 22:53:41.654 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2025-01-09 22:53:41.656 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:53:41.658 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2025-01-09 22:53:41.660 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:53:41.660 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2025-01-09 22:53:41.661 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:53:41.661 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2025-01-09 22:53:41.661 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2025-01-09 22:53:41.762 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 22:53:41.763 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 22:53:41.763 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 22:53:43.673 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:56:26.299 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 22:56:26.318 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 22:56:26.318 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 22:56:26.555 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2025-01-09 22:56:26.556 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:56:26.557 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2025-01-09 22:56:26.557 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:56:26.557 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2025-01-09 22:56:26.558 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 22:56:26.559 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2025-01-09 22:56:26.559 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2025-01-09 22:56:26.647 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 22:56:26.648 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 22:56:26.648 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 22:56:28.122 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 23:01:41.613 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 23:01:41.645 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2025-01-09 23:01:41.649 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 23:01:41.649 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 23:01:41.886 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2025-01-09 23:01:41.887 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 23:01:41.889 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2025-01-09 23:01:41.890 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 23:01:41.891 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2025-01-09 23:01:41.891 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torch\_ops.py", line 1350, in load_library
    ctypes.CDLL(path)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'D:\code\python\voice-agent\.venv\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2025-01-09 23:01:41.892 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2025-01-09 23:01:41.892 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2025-01-09 23:01:42.038 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 23:01:42.039 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 23:01:42.040 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 23:01:46.966 - RealTimeSTT: root - DEBUG - Main transcription model ready
2025-01-09 23:01:46.967 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2025-01-09 23:01:46.967 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:01:46.967 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:01:47.317 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:01:53.604 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:01:53.604 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:01:53.604 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:01:53.604 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:01:58.474 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:01:58.475 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:01:58.546 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:01:58.549 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:01:58.549 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:01:58.604 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:01:58.831 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.28 seconds
2025-01-09 23:01:58.832 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:01:58.832 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:01:58.833 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:02:02.954 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:02:02.954 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:02:02.954 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:02:02.954 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:02:09.355 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:02:09.355 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:02:09.430 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:02:09.431 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:02:09.431 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:02:09.485 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:02:09.677 - RealTimeSTT: root - DEBUG - Model tiny completed transcription in 0.25 seconds
2025-01-09 23:02:09.677 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:02:09.677 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:02:09.678 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:02:59.207 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2025-01-09 23:02:59.207 - RealTimeSTT: root - DEBUG - Finishing recording thread
2025-01-09 23:02:59.223 - RealTimeSTT: root - DEBUG - Terminating reader process
2025-01-09 23:02:59.619 - RealTimeSTT: root - DEBUG - Terminating transcription process
2025-01-09 23:02:59.781 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2025-01-09 23:02:59.888 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2025-01-09 23:03:36.812 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 23:03:36.816 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 23:03:36.816 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 23:03:37.135 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 23:03:37.136 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 23:03:37.136 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 23:03:55.611 - RealTimeSTT: root - DEBUG - Main transcription model ready
2025-01-09 23:03:55.612 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2025-01-09 23:03:55.614 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:03:55.615 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:03:56.004 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:05:05.910 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2025-01-09 23:05:05.910 - RealTimeSTT: root - DEBUG - Finishing recording thread
2025-01-09 23:05:05.926 - RealTimeSTT: root - DEBUG - Terminating reader process
2025-01-09 23:05:05.926 - RealTimeSTT: root - DEBUG - Terminating transcription process
2025-01-09 23:05:06.752 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2025-01-09 23:05:06.929 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2025-01-09 23:06:39.511 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 23:06:39.515 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 23:06:39.515 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 23:06:39.808 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 23:06:39.810 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 23:06:39.810 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 23:06:47.065 - RealTimeSTT: root - DEBUG - Main transcription model ready
2025-01-09 23:06:47.067 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2025-01-09 23:06:55.969 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:06:55.969 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:06:56.152 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:08:52.650 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2025-01-09 23:08:52.650 - RealTimeSTT: root - DEBUG - Receive from stdout pipe
2025-01-09 23:08:52.650 - RealTimeSTT: root - DEBUG - Finishing recording thread
2025-01-09 23:08:52.665 - RealTimeSTT: root - DEBUG - Terminating reader process
2025-01-09 23:08:52.665 - RealTimeSTT: root - DEBUG - Terminating transcription process
2025-01-09 23:08:53.478 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2025-01-09 23:12:02.412 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 23:12:02.416 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2025-01-09 23:12:02.419 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 23:12:02.419 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 23:12:02.685 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 23:12:02.686 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 23:12:02.686 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 23:12:09.753 - RealTimeSTT: root - DEBUG - Main transcription model ready
2025-01-09 23:12:09.754 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2025-01-09 23:12:09.754 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:12:09.777 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we've started a new conversation. How can I assist you today? Do you have a specific question or topic you'd like to discuss?"}, {'role': 'assistant', 'content': ' Thank you.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'user', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:12:09.781 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:12:09.783 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B4D785CB50>
2025-01-09 23:12:09.783 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:12:09.783 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:12:09.783 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:12:09.783 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:12:09.783 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:12:11.315 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:12:11 GMT'), (b'Content-Length', b'438')])
2025-01-09 23:12:11.315 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:12:11.315 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:12:11.315 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:12:11.315 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:12:11.315 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:12:11.315 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:12:11.324 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we've started a new conversation. How can I assist you today? Do you have a specific question or topic you'd like to discuss?"}, {'role': 'assistant', 'content': ' Thank you.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'user', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_a5qgovbm', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Sophie"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_a5qgovbm', 'content': 'Switched context to Sophie.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:12:11.324 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:12:11.325 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:12:11.325 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:12:11.325 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:12:11.325 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:12:11.580 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:12:11 GMT'), (b'Content-Length', b'517')])
2025-01-09 23:12:11.580 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:12:11.581 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:12:11.581 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:12:11.581 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:12:11.581 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:12:11.581 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:12:11.870 - RealTimeSTT: parler_tts.modeling_parler_tts - WARNING - `prompt_attention_mask` is specified but `attention_mask` is not. A full `attention_mask` will be created. Make sure this is the intended behaviour.
2025-01-09 23:12:28.847 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:12:28.859 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:12:28.860 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:12:28.860 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:12:28.861 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:12:28.871 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:12:28.872 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.498540 seconds
2025-01-09 23:12:29.374 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:12:29.375 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:12:29.376 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B52C177130>
2025-01-09 23:12:29.376 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:12:29.377 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:12:29.377 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:12:29.377 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:12:29.377 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:12:35.856 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:12:35 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:12:35.856 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:12:35.856 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:12:35.857 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:12:36.056 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:12:36.057 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:12:36.061 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:12:36.063 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:12:36.063 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:12:36.233 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:12:37.871 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:12:37.871 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:12:37.871 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:12:37.872 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:12:39.342 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:12:39.342 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:12:39.385 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:12:39.386 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:12:39.400 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:12:39.411 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:12:39.778 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:12:39.778 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:12:39.778 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:12:39.779 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:12:39.787 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'user', 'content': 'My name is Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:12:39.788 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:12:39.789 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B56335B9D0>
2025-01-09 23:12:39.789 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:12:39.789 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:12:39.789 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:12:39.790 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:12:39.790 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:12:41.701 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:12:41 GMT'), (b'Content-Length', b'437')])
2025-01-09 23:12:41.701 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:12:41.701 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:12:41.702 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:12:41.702 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:12:41.702 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:12:41.702 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:12:41.713 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'user', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_dfjxihi4', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Ash"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_dfjxihi4', 'content': 'Switched context to Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:12:41.713 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:12:41.714 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:12:41.714 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:12:41.714 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:12:41.714 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:12:42.133 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:12:42 GMT'), (b'Content-Length', b'714')])
2025-01-09 23:12:42.133 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:12:42.133 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:12:42.133 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:12:42.133 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:12:42.133 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:12:42.133 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:01.813 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:13:01.814 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:13:01.814 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:13:01.814 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:13:06.034 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:13:06.034 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:13:06.086 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:13:06.087 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:13:06.087 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:13:06.103 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:13:09.406 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:13:09.414 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:09.414 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:13:09.414 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:13:09.415 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:13:09.416 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:13:09.416 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.453104 seconds
2025-01-09 23:13:09.881 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:09.882 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:13:09.883 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B563383D00>
2025-01-09 23:13:09.883 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:09.883 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:09.883 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:09.884 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:09.884 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:14.947 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:13:14 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:13:14.947 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:14.947 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:14.948 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:14.977 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:14.977 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:14.988 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:13:14.991 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:13:14.991 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:13:14.992 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:13:14.992 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:13:14.999 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "Oh, I didn't get a call. I'm actually a programmer."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:14.999 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:13:15.000 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B56328CD90>
2025-01-09 23:13:15.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:15.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:15.001 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:15.001 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:15.001 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:16.935 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:13:16 GMT'), (b'Content-Length', b'436')])
2025-01-09 23:13:16.935 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:16.935 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:16.936 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:13:16.936 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:16.936 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:16.936 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:16.943 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_4p0cul2h', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Ash"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_4p0cul2h', 'content': 'Switched context to Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:16.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:16.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:16.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:16.944 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:16.944 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:17.175 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:13:17.175 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:13:17.175 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:13:17.175 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:13:17.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:13:17 GMT'), (b'Content-Length', b'536')])
2025-01-09 23:13:17.213 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:17.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:17.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:13:17.213 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:17.213 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:17.213 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:20.375 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:13:20.376 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:13:20.439 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:13:20.440 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:13:20.455 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:13:20.505 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:13:25.718 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:13:25.727 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:25.728 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:13:25.728 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:13:25.728 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:13:25.728 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:13:25.728 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.443826 seconds
2025-01-09 23:13:26.183 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:26.184 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:13:26.186 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B563396BF0>
2025-01-09 23:13:26.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:26.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:26.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:26.186 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:26.186 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:33.213 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:13:33 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:13:33.213 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:33.213 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:33.214 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:33.242 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:33.242 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:33.246 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:13:33.248 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:13:33.248 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:13:33.250 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:13:33.250 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:13:33.257 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "I'm actually a programmer."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:33.257 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:13:33.259 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B4D89DD5D0>
2025-01-09 23:13:33.259 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:33.259 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:33.259 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:33.260 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:33.260 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:35.191 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:13:35 GMT'), (b'Content-Length', b'443')])
2025-01-09 23:13:35.191 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:35.191 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:35.191 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:13:35.192 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:35.192 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:35.192 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:35.200 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "I'm actually a programmer."}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_jzzegh90', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"programmer"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_jzzegh90', 'content': 'Switched context to programmer.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:35.201 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:35.201 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:35.201 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:35.201 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:35.201 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:35.491 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:13:35 GMT'), (b'Content-Length', b'572')])
2025-01-09 23:13:35.491 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:35.492 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:35.492 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:13:35.492 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:35.492 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:35.492 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:51.575 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:13:51.579 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "So you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\nPlease provide more details about your current project or issue, and I'll do my best to assist you."}, {'role': 'assistant', 'content': "I'm actually a programmer."}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:51.580 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:13:51.580 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:13:51.580 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:13:51.580 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:13:51.580 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.425266 seconds
2025-01-09 23:13:52.003 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "So you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\nPlease provide more details about your current project or issue, and I'll do my best to assist you."}, {'role': 'assistant', 'content': "I'm actually a programmer."}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:13:52.004 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:13:52.006 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B563406080>
2025-01-09 23:13:52.006 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:13:52.006 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:13:52.006 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:13:52.006 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:13:52.006 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:13:54.998 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:13:54.998 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:13:54.998 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:13:54.998 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:13:58.308 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:13:58 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:13:58.308 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:13:58.308 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:13:58.309 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:13:58.338 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:13:58.338 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:13:58.342 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:14:01.978 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:14:01.979 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:14:02.046 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:14:02.047 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:14:02.077 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:14:02.108 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:14:02.496 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:14:02.496 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:14:02.496 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:14:02.497 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:14:02.499 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "So you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\nPlease provide more details about your current project or issue, and I'll do my best to assist you."}, {'role': 'assistant', 'content': "I'm actually a programmer."}, {'role': 'user', 'content': "No, I am just working on you actually I have I'm putting you together."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:02.500 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:14:02.502 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B563407A30>
2025-01-09 23:14:02.502 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:02.502 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:02.502 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:02.502 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:02.502 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:04.326 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:14:04 GMT'), (b'Content-Length', b'436')])
2025-01-09 23:14:04.326 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:04.326 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:04.326 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:14:04.326 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:04.326 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:04.326 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:04.331 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "So you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\nPlease provide more details about your current project or issue, and I'll do my best to assist you."}, {'role': 'assistant', 'content': "I'm actually a programmer."}, {'role': 'user', 'content': "No, I am just working on you actually I have I'm putting you together."}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_2tzvnoap', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"you"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_2tzvnoap', 'content': 'Switched context to you.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:04.332 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:04.332 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:04.332 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:04.332 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:04.332 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:04.529 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:14:04 GMT'), (b'Content-Length', b'462')])
2025-01-09 23:14:04.529 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:04.529 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:04.529 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:14:04.529 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:04.529 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:04.529 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:14.908 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:14:14.913 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like you're in the process of setting me up. How's that going? Do you need any help with anything specific or would you like some guidance on how to get started?"}, {'role': 'assistant', 'content': "No, I am just working on you actually I have I'm putting you together."}, {'role': 'assistant', 'content': "It seems we didn't get a specific question from you, could you please provide the user's original question so I can format an answer using the tool call response?"}, {'role': 'assistant', 'content': ' And you need me about that.'}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:14.914 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:14:14.914 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:14:14.915 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:14:14.916 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:14:14.916 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.499658 seconds
2025-01-09 23:14:15.423 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like you're in the process of setting me up. How's that going? Do you need any help with anything specific or would you like some guidance on how to get started?"}, {'role': 'assistant', 'content': "No, I am just working on you actually I have I'm putting you together."}, {'role': 'assistant', 'content': "It seems we didn't get a specific question from you, could you please provide the user's original question so I can format an answer using the tool call response?"}, {'role': 'assistant', 'content': ' And you need me about that.'}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:15.423 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:14:15.426 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B56338A620>
2025-01-09 23:14:15.426 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:15.426 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:15.426 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:15.426 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:15.426 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:19.130 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:14:19.131 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:14:19.131 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:14:19.131 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:14:21.115 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:14:21 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:14:21.115 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:21.116 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:21.116 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:21.272 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:21.272 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:21.283 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:14:24.700 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:14:24.700 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:14:24.799 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:14:24.800 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:14:24.800 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:14:24.830 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:14:25.206 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:14:25.206 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:14:25.206 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:14:25.207 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:14:25.211 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like you're in the process of setting me up. How's that going? Do you need any help with anything specific or would you like some guidance on how to get started?"}, {'role': 'assistant', 'content': "No, I am just working on you actually I have I'm putting you together."}, {'role': 'assistant', 'content': "It seems we didn't get a specific question from you, could you please provide the user's original question so I can format an answer using the tool call response?"}, {'role': 'assistant', 'content': ' And you need me about that.'}, {'role': 'user', 'content': "No, I think I'm doing pretty good. This is actually working."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:25.211 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:14:25.213 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B5633EE3B0>
2025-01-09 23:14:25.213 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:25.214 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:25.214 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:25.214 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:25.214 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:27.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:14:27 GMT'), (b'Content-Length', b'458')])
2025-01-09 23:14:27.076 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:27.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:27.076 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:14:27.076 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:27.076 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:27.076 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:27.083 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like you're in the process of setting me up. How's that going? Do you need any help with anything specific or would you like some guidance on how to get started?"}, {'role': 'assistant', 'content': "No, I am just working on you actually I have I'm putting you together."}, {'role': 'assistant', 'content': "It seems we didn't get a specific question from you, could you please provide the user's original question so I can format an answer using the tool call response?"}, {'role': 'assistant', 'content': ' And you need me about that.'}, {'role': 'user', 'content': "No, I think I'm doing pretty good. This is actually working."}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_os3gaiek', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"\\u003cuser\'s name\\u003e"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_os3gaiek', 'content': "Switched context to <user's name>."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:27.084 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:27.085 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:27.085 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:27.085 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:27.085 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:27.338 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:14:27 GMT'), (b'Content-Length', b'528')])
2025-01-09 23:14:27.339 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:27.339 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:27.339 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:14:27.339 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:27.339 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:27.339 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:42.629 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:14:42.633 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we're all set! You've successfully initiated the tool calling process. What's the next step? Do you have a specific question or topic in mind that you'd like me to assist with, or would you like me to suggest some options?"}, {'role': 'assistant', 'content': "No, I think I'm doing pretty good. This is actually working."}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:42.633 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:14:42.633 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:14:42.634 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:14:42.635 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:14:42.635 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.427639 seconds
2025-01-09 23:14:43.070 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we're all set! You've successfully initiated the tool calling process. What's the next step? Do you have a specific question or topic in mind that you'd like me to assist with, or would you like me to suggest some options?"}, {'role': 'assistant', 'content': "No, I think I'm doing pretty good. This is actually working."}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:43.071 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:14:43.072 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B5633F0DF0>
2025-01-09 23:14:43.072 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:43.073 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:43.073 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:43.073 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:43.073 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:48.192 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:14:48.192 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:14:48.193 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:14:48.193 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:14:48.716 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:14:48 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:14:48.716 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:48.716 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:48.716 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:48.747 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:48.748 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:48.753 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:14:50.682 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:14:50.682 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:14:50.746 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:14:50.747 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:14:50.752 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:14:50.777 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:14:51.058 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:14:51.059 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:14:51.059 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:14:51.059 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:14:51.062 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we're all set! You've successfully initiated the tool calling process. What's the next step? Do you have a specific question or topic in mind that you'd like me to assist with, or would you like me to suggest some options?"}, {'role': 'assistant', 'content': "No, I think I'm doing pretty good. This is actually working."}, {'role': 'user', 'content': 'Sure, suggest a way.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:51.063 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:14:51.064 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B5633F3670>
2025-01-09 23:14:51.064 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:51.064 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:51.065 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:51.065 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:51.065 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:52.919 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:14:52 GMT'), (b'Content-Length', b'454')])
2025-01-09 23:14:52.919 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:52.920 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:52.920 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:14:52.920 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:52.920 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:52.920 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:14:52.924 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we're all set! You've successfully initiated the tool calling process. What's the next step? Do you have a specific question or topic in mind that you'd like me to assist with, or would you like me to suggest some options?"}, {'role': 'assistant', 'content': "No, I think I'm doing pretty good. This is actually working."}, {'role': 'user', 'content': 'Sure, suggest a way.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_uniikz1s', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"\\u003cunknown\\u003e"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_uniikz1s', 'content': 'Switched context to <unknown>.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:14:52.925 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:14:52.926 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:14:52.926 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:14:52.926 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:14:52.926 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:14:53.408 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:14:53 GMT'), (b'Content-Length', b'781')])
2025-01-09 23:14:53.409 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:14:53.409 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:14:53.409 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:14:53.409 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:14:53.409 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:14:53.409 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:15:24.700 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:15:24.706 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like the tool call was not successful. Let me try again.\n\nTo get started, you can type a question or ask for help with a specific topic. I'll do my best to provide a helpful response.\n\nIf you need assistance with a particular task or problem, feel free to describe it in detail and I'll do my best to provide a solution.\n\nAlternatively, if you'd like to explore a new topic or learn something new, just let me know what's on your mind!\n\nWhat would you like to talk about?"}, {'role': 'assistant', 'content': 'Sure, suggest a way.'}, {'role': 'assistant', 'content': "It seems we've started fresh!\n\nYou'd like me to assist with a tool call response, but you haven't provided one yet. Please go ahead and share the output of the tool call response, and I'll do my best to format an answer based on your original user question."}, {'role': 'assistant', 'content': ' Go!'}, {'role': 'assistant', 'content': 'User question: "System startup complete. You have just been activated. Welcome to the world, I\'m a big fan of Star Wars. Can you recommend some Star Wars movies?"'}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:15:24.707 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:15:24.707 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:15:24.707 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:15:24.708 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:15:24.708 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.417188 seconds
2025-01-09 23:15:25.136 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like the tool call was not successful. Let me try again.\n\nTo get started, you can type a question or ask for help with a specific topic. I'll do my best to provide a helpful response.\n\nIf you need assistance with a particular task or problem, feel free to describe it in detail and I'll do my best to provide a solution.\n\nAlternatively, if you'd like to explore a new topic or learn something new, just let me know what's on your mind!\n\nWhat would you like to talk about?"}, {'role': 'assistant', 'content': 'Sure, suggest a way.'}, {'role': 'assistant', 'content': "It seems we've started fresh!\n\nYou'd like me to assist with a tool call response, but you haven't provided one yet. Please go ahead and share the output of the tool call response, and I'll do my best to format an answer based on your original user question."}, {'role': 'assistant', 'content': ' Go!'}, {'role': 'assistant', 'content': 'User question: "System startup complete. You have just been activated. Welcome to the world, I\'m a big fan of Star Wars. Can you recommend some Star Wars movies?"'}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:15:25.137 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:15:25.138 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001B563407F70>
2025-01-09 23:15:25.138 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:15:25.139 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:15:25.139 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:15:25.139 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:15:25.139 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:15:30.795 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:15:30 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:15:30.795 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:15:30.795 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:15:30.795 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:15:31.953 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:15:31.953 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:15:31.958 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:16:07.473 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2025-01-09 23:16:07.473 - RealTimeSTT: root - DEBUG - Finishing recording thread
2025-01-09 23:16:07.488 - RealTimeSTT: root - DEBUG - Terminating reader process
2025-01-09 23:16:08.432 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2025-01-09 23:16:27.225 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2025-01-09 23:16:27.229 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2025-01-09 23:16:27.232 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2025-01-09 23:16:27.232 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2025-01-09 23:16:27.470 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2025-01-09 23:16:27.473 - RealTimeSTT: root - DEBUG - Starting realtime worker
2025-01-09 23:16:27.473 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2025-01-09 23:16:34.959 - RealTimeSTT: root - DEBUG - Main transcription model ready
2025-01-09 23:16:34.960 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2025-01-09 23:16:34.960 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:16:34.976 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we've started a new conversation. How can I assist you today? Do you have a specific question or topic you'd like to discuss?"}, {'role': 'assistant', 'content': ' Thank you.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'user', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:16:34.981 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:16:34.983 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019DD69ACBE0>
2025-01-09 23:16:34.983 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:16:34.983 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:16:34.983 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:16:34.983 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:16:34.983 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:16:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:16:36 GMT'), (b'Content-Length', b'439')])
2025-01-09 23:16:36.842 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:16:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:16:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:16:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:16:36.842 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:16:36.842 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:16:36.851 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we've started a new conversation. How can I assist you today? Do you have a specific question or topic you'd like to discuss?"}, {'role': 'assistant', 'content': ' Thank you.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': '(System startup complete.) You have just been activated. Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown.'}, {'role': 'user', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_s28djxyd', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Sophie"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_s28djxyd', 'content': 'Switched context to Sophie.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:16:36.851 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:16:36.852 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:16:36.852 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:16:36.852 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:16:36.852 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:16:37.058 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:16:37 GMT'), (b'Content-Length', b'478')])
2025-01-09 23:16:37.058 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:16:37.058 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:16:37.058 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:16:37.059 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:16:37.059 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:16:37.059 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:16:37.407 - RealTimeSTT: parler_tts.modeling_parler_tts - WARNING - `prompt_attention_mask` is specified but `attention_mask` is not. A full `attention_mask` will be created. Make sure this is the intended behaviour.
2025-01-09 23:16:52.332 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:16:52.347 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show the proper level of respect."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:16:52.347 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:16:52.347 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:16:52.348 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:16:52.352 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:16:52.352 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.464904 seconds
2025-01-09 23:16:52.821 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show the proper level of respect."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:16:52.821 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:16:52.823 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019DD69751B0>
2025-01-09 23:16:52.823 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:16:52.823 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:16:52.823 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:16:52.823 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:16:52.823 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:16:58.435 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:16:58 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:16:58.435 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:16:58.435 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:16:58.436 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:16:59.428 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:16:59.429 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:16:59.434 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:16:59.435 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:16:59.435 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:16:59.435 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:17:00.425 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:17:00.425 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:17:00.425 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:17:00.426 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:17:01.835 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:17:01.835 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:17:01.835 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:17:01.835 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:17:01.848 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:17:01.905 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:17:02.399 - RealTimeSTT: root - DEBUG - Model small completed transcription in 0.56 seconds
2025-01-09 23:17:02.457 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:17:02.457 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:17:02.457 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:17:02.457 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:17:02.467 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show the proper level of respect."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'user', 'content': 'My name is Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:17:02.468 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:17:02.469 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019DD69AD390>
2025-01-09 23:17:02.469 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:17:02.469 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:17:02.469 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:17:02.470 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:17:02.470 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:17:04.444 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:17:04 GMT'), (b'Content-Length', b'438')])
2025-01-09 23:17:04.444 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:17:04.444 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:17:04.444 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:17:04.444 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:17:04.444 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:17:04.444 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:17:04.455 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show the proper level of respect."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I address you correctly and show you that I care about getting to know you better. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. My top priority is indeed getting to know the person I'm speaking with. To begin, could you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To get started, could you please tell me your name? I want to make sure I'm addressing the right person and getting to know you better."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're starting this conversation. To make things easier, let's get started with something simple. Can you please tell me your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "It seems I had a momentary lapse. Let's get back on track!\n\nTo answer your original question, I'm happy to help you with whatever tool-related issue you're facing. Could you please provide more details about the call you received and what specifically you'd like me to assist with? I'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': ' What?'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sofia. What's your name?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm so glad we're talking. My name is Sophia, but please call me Sophie. I'm excited to get to know you better and learn more about your life. Can you tell me a little bit about yourself? What do you like to do in your free time?"}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'assistant', 'content': "Hello! I'm glad you're ready to get to know me. My top priority is to understand your needs and provide the best possible assistance.\n\nTo start, can you please tell me your name? I want to make sure I address you correctly and show you that I care about who I'm talking to."}, {'role': 'assistant', 'content': '[system] Welcome to the world, Sophie. Make sure to figure out who it is you are speaking to, currently unknown. Your top priority is to get to know the person you are speaking to. You can ask questions to learn more about them, start by asking their name.'}, {'role': 'user', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_i5k8kxdz', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Ash"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_i5k8kxdz', 'content': 'Switched context to Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:17:04.456 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:17:04.456 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:17:04.456 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:17:04.456 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:17:04.456 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:17:04.811 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:17:04 GMT'), (b'Content-Length', b'601')])
2025-01-09 23:17:04.811 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:17:04.811 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:17:04.812 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:17:04.812 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:17:04.812 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:17:04.812 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:17:25.820 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:17:25.832 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:17:25.832 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:17:25.832 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:17:25.833 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:17:25.833 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:17:25.833 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.396078 seconds
2025-01-09 23:17:26.239 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:17:26.240 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:17:26.241 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019E2B0BA620>
2025-01-09 23:17:26.241 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:17:26.242 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:17:26.242 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:17:26.242 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:17:26.242 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:17:31.454 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:17:31 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:17:31.454 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:17:31.454 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:17:31.454 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:17:31.788 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:17:31.788 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:17:31.788 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:17:31.788 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:17:32.651 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:17:32.651 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:17:32.662 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:17:33.008 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:17:33.008 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:17:33.008 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:17:33.008 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:17:33.012 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:17:33.068 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:17:33.072 - RealTimeSTT: root - DEBUG - Model small completed transcription in 0.06 seconds
2025-01-09 23:17:33.170 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:17:33.170 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:17:33.170 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:17:33.170 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:17:33.178 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "I don't know."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:17:33.178 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:17:33.180 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019E2B0BED40>
2025-01-09 23:17:33.180 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:17:33.180 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:17:33.180 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:17:33.180 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:17:33.180 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:17:33.268 - RealTimeSTT: root - INFO - voice activity detected
2025-01-09 23:17:33.268 - RealTimeSTT: root - INFO - recording started
2025-01-09 23:17:33.268 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2025-01-09 23:17:33.268 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2025-01-09 23:17:35.126 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:17:35 GMT'), (b'Content-Length', b'434')])
2025-01-09 23:17:35.126 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:17:35.126 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:17:35.126 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:17:35.126 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:17:35.126 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:17:35.126 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:17:35.135 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "I don't know."}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_2aukyfba', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Ash"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_2aukyfba', 'content': 'Switched context to Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:17:35.136 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:17:35.136 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:17:35.136 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:17:35.136 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:17:35.136 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:17:35.592 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:17:35 GMT'), (b'Content-Length', b'751')])
2025-01-09 23:17:35.592 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:17:35.592 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:17:35.592 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:17:35.592 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:17:35.592 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:17:35.592 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:17:36.658 - RealTimeSTT: root - INFO - recording stopped
2025-01-09 23:17:36.659 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2025-01-09 23:17:36.659 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2025-01-09 23:17:36.659 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2025-01-09 23:17:36.659 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2025-01-09 23:17:36.719 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2025-01-09 23:17:36.783 - RealTimeSTT: root - DEBUG - Model small completed transcription in 0.12 seconds
2025-01-09 23:18:04.347 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:18:04.359 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It can be overwhelming with so many options and possibilities.\n\nLet's start again from the beginning. What brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nIf you're not sure where to start, we can explore some general topics together. What are some things that interest you or have been on your mind lately?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:18:04.359 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:18:04.359 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:18:04.360 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:18:04.360 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:18:04.360 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.465306 seconds
2025-01-09 23:18:04.829 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It can be overwhelming with so many options and possibilities.\n\nLet's start again from the beginning. What brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nIf you're not sure where to start, we can explore some general topics together. What are some things that interest you or have been on your mind lately?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:18:04.830 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:18:04.832 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019E2B0B9000>
2025-01-09 23:18:04.832 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:18:04.832 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:18:04.832 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:18:04.833 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:18:04.833 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:18:11.396 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:18:11 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:18:11.397 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:18:11.397 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:18:11.397 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:18:11.427 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:18:11.427 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:18:11.438 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
2025-01-09 23:18:11.441 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:18:11.441 - RealTimeSTT: root - INFO - Setting listen time
2025-01-09 23:18:11.441 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2025-01-09 23:18:11.441 - RealTimeSTT: root - DEBUG - Waiting for recording start
2025-01-09 23:18:11.450 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It can be overwhelming with so many options and possibilities.\n\nLet's start again from the beginning. What brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nIf you're not sure where to start, we can explore some general topics together. What are some things that interest you or have been on your mind lately?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "I don't know."}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:18:11.450 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:18:11.452 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019D0DA0AE30>
2025-01-09 23:18:11.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:18:11.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:18:11.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:18:11.452 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:18:11.452 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:18:13.349 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:18:13 GMT'), (b'Content-Length', b'435')])
2025-01-09 23:18:13.350 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:18:13.350 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:18:13.350 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:18:13.350 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:18:13.350 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:18:13.351 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:18:13.362 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It can be overwhelming with so many options and possibilities.\n\nLet's start again from the beginning. What brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nIf you're not sure where to start, we can explore some general topics together. What are some things that interest you or have been on your mind lately?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'user', 'content': "I don't know."}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_5h7wm5ko', 'type': 'function', 'function': {'name': 'set_user_context', 'arguments': '{"user":"Ash"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_5h7wm5ko', 'content': 'Switched context to Ash.'}], 'model': 'llama3.2:latest', 'max_tokens': 32000, 'n': 1, 'parallel_tool_calls': True, 'stream': False, 'temperature': 0.4, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'set_user_context', 'description': "Switch memory context to a user-specific one. \nThis is useful for personalized conversations. \nOnly run this tool when the user's name is known or when the user clarifies their name.", 'parameters': {'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:18:13.363 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:18:13.363 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:18:13.363 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:18:13.363 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:18:13.363 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:18:13.827 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Date', b'Fri, 10 Jan 2025 07:18:13 GMT'), (b'Content-Length', b'776')])
2025-01-09 23:18:13.828 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:18:13.828 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:18:13.828 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2025-01-09 23:18:13.828 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:18:13.828 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:18:13.828 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:18:45.195 - RealTimeSTT: asyncio - DEBUG - Using proactor: IocpProactor
2025-01-09 23:18:45.208 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we've started a conversation, but I didn't receive any specific question or topic from you. Let's start fresh!\n\nIf you're feeling unsure about what to talk about, I can suggest some topics. We could discuss programming languages, new technologies, or even explore some fun projects together.\n\nOr, if you'd rather not think about anything in particular, we could play a game or have a casual conversation. What sounds interesting to you?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "It can be overwhelming with so many options and possibilities.\n\nLet's start again from the beginning. What brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nIf you're not sure where to start, we can explore some general topics together. What are some things that interest you or have been on your mind lately?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:18:45.208 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2025-01-09 23:18:45.208 - RealTimeSTT: httpcore.connection - DEBUG - close.failed exception=RuntimeError('Event loop is closed')
2025-01-09 23:18:45.209 - RealTimeSTT: openai._base_client - DEBUG - Encountered Exception
Traceback (most recent call last):
  File "D:\code\python\voice-agent\.venv\lib\site-packages\openai\_base_client.py", line 1576, in _request
    response = await self._client.send(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1674, in send
    response = await self._send_handling_auth(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1702, in _send_handling_auth
    response = await self._send_handling_redirects(
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1739, in _send_handling_redirects
    response = await self._send_single_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_client.py", line 1776, in _send_single_request
    response = await transport.handle_async_request(request)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpx\_transports\default.py", line 377, in handle_async_request
    resp = await self._pool.handle_async_request(req)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 229, in handle_async_request
    await self._close_connections(closing)
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection_pool.py", line 345, in _close_connections
    await connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\connection.py", line 173, in aclose
    await self._connection.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_async\http11.py", line 258, in aclose
    await self._network_stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\httpcore\_backends\anyio.py", line 53, in aclose
    await self._stream.aclose()
  File "D:\code\python\voice-agent\.venv\lib\site-packages\anyio\_backends\_asyncio.py", line 1349, in aclose
    self._transport.close()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\proactor_events.py", line 109, in close
    self._loop.call_soon(self._call_connection_lost, None)
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 753, in call_soon
    self._check_closed()
  File "C:\Users\pie_l\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 515, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
2025-01-09 23:18:45.209 - RealTimeSTT: openai._base_client - DEBUG - 2 retries left
2025-01-09 23:18:45.210 - RealTimeSTT: openai._base_client - INFO - Retrying request to /chat/completions in 0.432024 seconds
2025-01-09 23:18:45.652 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "It seems like we've started a conversation, but I didn't receive any specific question or topic from you. Let's start fresh!\n\nIf you're feeling unsure about what to talk about, I can suggest some topics. We could discuss programming languages, new technologies, or even explore some fun projects together.\n\nOr, if you'd rather not think about anything in particular, we could play a game or have a casual conversation. What sounds interesting to you?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "It can be overwhelming with so many options and possibilities.\n\nLet's start again from the beginning. What brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nIf you're not sure where to start, we can explore some general topics together. What are some things that interest you or have been on your mind lately?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "I don't know."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your identity. Now that we have that out of the way, what brings you here today? Are you looking for help with a specific tool or project? Please feel free to share more about your needs, and I'll do my best to assist you.\n\nWhat would you like to know or discuss, Ash?"}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Hello! I'm glad we cleared that up. So, you're a programmer, huh? What's been the most interesting project you've worked on recently? Is there something specific you're struggling with or would like some advice on?\n\n( waiting for user input )"}, {'role': 'assistant', 'content': "Oh, I didn't get a call. I'm actually a programmer."}, {'role': 'assistant', 'content': "Hello Ash! I'm glad we've established your name. Now that we have a better understanding of who you are, let's get started on addressing the issue at hand.\n\nCould you please provide more details about the tool-related call you received? What was the purpose of the call, and what specifically were you trying to accomplish or resolve?\n\nI'll do my best to format an answer based on the output of the tool call response."}, {'role': 'assistant', 'content': 'My name is Ash.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! I'm glad we could establish your identity.\n\nSo, what brings you here today? Are you looking for help with something specific or just wanting to chat? I'm all ears (or rather, all text) and ready to assist you in any way I can."}, {'role': 'assistant', 'content': ' My name is Ash.'}, {'role': 'assistant', 'content': 'It seems like we\'ve established that you enjoy programming and exploring the world of natural language processing. That\'s awesome!\n\nIf you don\'t mind me asking, what kind of projects have you been working on lately? Are you building anything exciting or just tinkering with some new ideas?\n\nAlso, I noticed you mentioned "dopamine rush" earlier. Have you heard about the concept of "flow state" in the context of productivity and creativity? It\'s a fascinating topic that might interest you.\n\nLet me know if you\'d like to discuss more about programming, language models, or anything else that\'s on your mind!'}, {'role': 'assistant', 'content': ' Oh yeah, definitely.'}, {'role': 'assistant', 'content': 'The thrill of watching code come together is indeed exhilarating! It\'s like solving a puzzle, and when it finally works, it\'s a great feeling.\n\nFor those who might not know, the "dopamine rush" you mentioned is often referred to as the "flow state." It\'s a mental state where one becomes fully engaged in an activity, losing track of time and experiencing heightened focus and productivity. Many programmers, artists, and creatives report feeling this way when they\'re deeply immersed in their work.\n\nDo you find that your projects are more successful when you\'re working on them during the flow state?'}, {'role': 'assistant', 'content': ' Yeah, a little bit of all of the above. I enjoy the dopamine rush when something starts to work.'}, {'role': 'assistant', 'content': "Nice to meet you, Ash! It sounds like you're a tech-savvy individual who enjoys exploring the world of programming and natural language processing. Large language models like myself can be quite fascinating, can't they?\n\nWhat's your favorite thing about programming? Are you more into building applications, working on algorithms, or perhaps experimenting with new technologies?"}, {'role': 'assistant', 'content': ' My name is Ash and I like to program and play with large language models in my free time.'}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'assistant', 'content': ''}, {'role': 'user', 'content': 'Reflect on how Sophie can improve.'}], 'model': 'mychen76/llama3.1-intuitive-thinker:chain-of-thoughts.q4', 'n': 1, 'parallel_tool_calls': True, 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'summarize_memory', 'description': 'Summarize all messages for the current user.', 'parameters': {'properties': {}, 'type': 'object', 'additionalProperties': False}}}]}}
2025-01-09 23:18:45.653 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=5 socket_options=None
2025-01-09 23:18:45.655 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000019D0DA084F0>
2025-01-09 23:18:45.655 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-01-09 23:18:45.655 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2025-01-09 23:18:45.655 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-01-09 23:18:45.655 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2025-01-09 23:18:45.655 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-01-09 23:18:48.808 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2025-01-09 23:18:48.809 - RealTimeSTT: root - DEBUG - Finishing recording thread
2025-01-09 23:18:48.823 - RealTimeSTT: root - DEBUG - Terminating reader process
2025-01-09 23:18:49.955 - RealTimeSTT: root - DEBUG - Terminating transcription process
2025-01-09 23:18:50.033 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2025-01-09 23:18:50.221 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2025-01-09 23:18:50.458 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/event-stream'), (b'Date', b'Fri, 10 Jan 2025 07:18:50 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-01-09 23:18:50.458 - RealTimeSTT: httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-09 23:18:50.458 - RealTimeSTT: openai._base_client - DEBUG - HTTP Request: POST http://localhost:11434/v1/chat/completions "200 OK"
2025-01-09 23:18:50.459 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-01-09 23:18:50.488 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2025-01-09 23:18:50.488 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2025-01-09 23:18:50.498 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.failed exception=GeneratorExit()
